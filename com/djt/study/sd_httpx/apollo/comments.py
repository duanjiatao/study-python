# 注释常量
comments = {
    'bootstrap.servers': 'kafka集群地址',
    'topic.event': 'kafka事件流水topic',
    'group.id': 'kafka消费者组',
    'enable.auto.commit': 'kafka是否自动提交',
    'auto.commit.interval.ms': 'kafka自动提交时间间隔',
    'auto.offset.reset': 'kafka消费策略',
    'session.timeout.ms': 'kafka检测consumer是否挂掉超时时间',
    'heartbeat.interval.ms': 'kafka consumer心跳时间间隔',
    'max.poll.interval.ms': 'kafka consumer两次poll的最大时间间隔',
    'max.poll.records': 'kafka 一次poll返回的最大记录数',
    'topic.stat': 'kafka 事件流水下发topic',
    'acks': 'kafka Producer确认机制',
    'retries': 'kafka Producer重试次数',
    'compression.type': 'kafka Producer消息压缩方式',
    'batch.size': 'kafka Producer批次大小',
    'linger.ms': 'kafka Producer发送最大时间间隔',
    'buffer.memory': 'kafka Producer缓冲区大小',
    'max.in.flight.requests.per.connection': 'kafka 单个连接上能够发送的未响应请求的个数 可避免消息乱序',
    'hbase.zookeeper.quorum': 'hbase 集群zk地址',
    'hbase.zookeeper.property.clientPort': 'hbase 集群zk端口',
    'flink.checkpoint.path': 'flink checkpoint路径',
    'http.rule.url': 'http 统计规则接口URL',
    'flink.watermark.interval': 'flink watermark生成时间间隔',
    'execution.checkpointing.mode': 'flink checkpoint模式',
    'execution.checkpointing.interval': 'flink checkpoint生成时间间隔',
    'execution.checkpointing.timeout': 'flink checkpoint超时时间',
    'execution.checkpointing.max-concurrent-checkpoints': 'flink 同一时间允许的checkpoint个数',
    'execution.checkpointing.min-pause': 'flink 两个checkpoint之间的最小时间间隔',
    'execution.checkpointing.tolerable-failed-checkpoints': 'flink 最大可容忍连续失败checkpoint个数',
    'execution.checkpointing.externalized-checkpoint-retention': 'flink checkpoint保存策略',
    'flink.env.parallelism': 'flink 算子默认并行度',
    'flink.aggregate.parallelism': 'flink 聚合计算并行度',
    'flink.source.kafka.parallelism': 'flink kafka数据源并行度（与kafka分区数保持一致）',
    'flink.print.log': 'flink 是否打印数据日志',
    'restart-strategy': 'flink 重启策略',
    'restart-strategy.failure-rate.max-failures-per-interval': 'flink 固定时间间隔内允许的最大重启次数',
    'restart-strategy.failure-rate.failure-rate-interval': 'flink 重启固定时间间隔 ms',
    'restart-strategy.failure-rate.delay': 'flink 连续两次重启尝试之间的延迟时间 ms',
    'flink.agg.window.lateness.seconds': 'Flink 聚合窗口允许迟到时间',
    'flink.agg.window.bounded.seconds': 'Flink 统计窗口允许乱序时间',
    'request.timeout.ms': 'Kafka 请求超时',
    'flink.state.backend': 'Flink StateBackend（可选 FsStateBackend 或 RocksDBStateBackend）',
    'flink.checkpoint.unaligned.enable': 'Flink unaligned checkpoint',
    'rule.update.interval.seconds': '统计规则刷新时间间隔',
    'hbase.table.stat': 'HBase 统计表',
    'hbase.save.ttl.days': 'HBase 数据保存天数(时间窗口,全局窗口)',
    'hbase.rpc.timeout': 'HBase 单次RPC请求超时时间 ms',
    'hbase.client.retries.number': 'HBase 客户端最大重试次数',
    'hbase.client.operation.timeout': 'HBase 客户端单次操作超时时间 ms',
    'retry.backoff.ms': 'kafka重试时间间隔',
    'hbase.hconnection.threads.max': 'HBase连接最大线程数',
    'hbase.hconnection.threads.core': 'HBase连接核心线程数',
    'stat.group.parallelism.ratio': '分组统计并行度占比(即每个分组统计并行度占最大统计并行度的占比)',
    'hbase.rpc.client.impl': 'HBase-rpc客户端实现类',
    'hbase.client.ipc.pool.type': 'HBase客户端连接池类型',
    'hbase.client.ipc.pool.size': 'HBase客户端连接池大小',
    'flink.sink.kafka.parallelism': 'Flink kafka sink并行度',
    'topic.event.payment': 'kafka代付流水topic',
    'topic.stat.payment': 'kafka代付统计结果发送topic',
    'hbase.table.stat.payment': 'HBase 统计表(代付)',
    'stat.event.type': '统计事件类型',
    'stat.pool.ruleNumsPerThread': '单线程可以处理的规则数(用于确定统计线程池大小)',
    'hbase.client.keyvalue.maxsize': 'HBase单个put最大字节数',
    'stat.pool.timeout.seconds': '统计线程池等待超时(单位:秒)',
    'stat.pool.queueSize.multiple': '任务队列是核心线程数的倍数(用于确定线程池队列大小)',
    'hive.table.stat': 'Hive统计结果表',
    '_hive.hdfs.session.path': 'Flink-Hive HDFS会话路径',
    'table.exec.hive.fallback-mapred-writer': 'Flink写Hive的方式是否是MR writer',
    'hive.jdbc.url': 'Hive jdbc url',
    'hive.view.stat': 'Hive统计结果表对应的视图'
}
